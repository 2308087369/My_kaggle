{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8926339,"sourceType":"datasetVersion","datasetId":5369298},{"sourceId":187760598,"sourceType":"kernelVersion"}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, LSTM, Input, concatenate\nfrom tensorflow.keras.optimizers import Adam\n\n# 数据预处理函数\ndef preprocess_data(df):\n    label_enc = LabelEncoder()\n    categorical_columns = ['Gender', 'Vehicle_Age', 'Vehicle_Damage']\n    for col in categorical_columns:\n        df[col] = label_enc.fit_transform(df[col])\n    df.fillna(df.median(), inplace=True)\n    return df\n\n# 导入数据\ntrain_df0 = pd.read_csv('/kaggle/input/binary/train.csv/train.csv')\ntest_df0 = pd.read_csv('/kaggle/input/binary/test.csv/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-11T06:46:57.223821Z","iopub.execute_input":"2024-07-11T06:46:57.224570Z","iopub.status.idle":"2024-07-11T06:47:43.294444Z","shell.execute_reply.started":"2024-07-11T06:46:57.224526Z","shell.execute_reply":"2024-07-11T06:47:43.293594Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-07-11 06:46:59.967488: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-11 06:46:59.967595: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-11 06:47:00.088925: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# 从训练集中提取200000个数据\ntrain_df = train_df0.sample(n=200000, random_state=42)\nextra_train_df = train_df0.drop(train_df.index).sample(n=100000, random_state=42)\n\n# 数据预处理\ntrain_df = preprocess_data(train_df)\nextra_train_df = preprocess_data(extra_train_df)\ntest_df = preprocess_data(test_df0)\n\n# 特征和目标变量\nX = train_df.drop(columns=['Response', 'id'])\ny = train_df['Response']\nextra_X = extra_train_df.drop(columns=['Response', 'id'])\nextra_y = extra_train_df['Response']\ntest_X = test_df.drop(columns=['id'])\n\n# 特征标准化\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nextra_X_scaled = scaler.transform(extra_X)\ntest_X_scaled = scaler.transform(test_X)\n\n# PCA降维\npca = PCA(n_components=0.95)\nX_pca = pca.fit_transform(X_scaled)\nextra_X_pca = pca.transform(extra_X_scaled)\ntest_X_pca = pca.transform(test_X_scaled)\n\n# 将特征扩展到3D以适应Conv1D和LSTM\nX_pca = np.expand_dims(X_pca, axis=2)\nextra_X_pca = np.expand_dims(extra_X_pca, axis=2)\ntest_X_pca = np.expand_dims(test_X_pca, axis=2)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T06:47:46.548653Z","iopub.execute_input":"2024-07-11T06:47:46.549021Z","iopub.status.idle":"2024-07-11T06:47:58.840584Z","shell.execute_reply.started":"2024-07-11T06:47:46.548993Z","shell.execute_reply":"2024-07-11T06:47:58.839236Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# 构建CNN-LSTM模型\ndef build_cnn_lstm_model(input_shape):\n    model = Sequential()\n    model.add(Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=input_shape))\n    model.add(LSTM(70, return_sequences=True))\n    model.add(LSTM(70))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(1, activation='sigmoid'))\n    return model\n\n# 构建双层LSTM模型\ndef build_two_layer_lstm_model(input_shape):\n    model = Sequential()\n    model.add(LSTM(70, return_sequences=True, input_shape=input_shape))\n    model.add(LSTM(70))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(1, activation='sigmoid'))\n    return model\n\n# 构建单层LSTM模型\ndef build_single_layer_lstm_model(input_shape):\n    model = Sequential()\n    model.add(LSTM(70, input_shape=input_shape))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(1, activation='sigmoid'))\n    return model\n\ninput_shape = (X_pca.shape[1], 1)\n\ncnn_lstm_model = build_cnn_lstm_model(input_shape)\ntwo_layer_lstm_model = build_two_layer_lstm_model(input_shape)\nsingle_layer_lstm_model = build_single_layer_lstm_model(input_shape)\n\ncnn_lstm_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\ntwo_layer_lstm_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\nsingle_layer_lstm_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n\n# 训练三个子模型\ncnn_lstm_model.fit(X_pca, y, epochs=10, batch_size=32, validation_split=0.2)\ntwo_layer_lstm_model.fit(X_pca, y, epochs=10, batch_size=32, validation_split=0.2)\nsingle_layer_lstm_model.fit(X_pca, y, epochs=10, batch_size=32, validation_split=0.2)\n\n# 获取三个子模型的预测结果\ncnn_lstm_predictions = cnn_lstm_model.predict(extra_X_pca)\ntwo_layer_lstm_predictions = two_layer_lstm_model.predict(extra_X_pca)\nsingle_layer_lstm_predictions = single_layer_lstm_model.predict(extra_X_pca)\n\n# 组合预测结果作为新特征\nstacked_features = np.concatenate([cnn_lstm_predictions, two_layer_lstm_predictions, single_layer_lstm_predictions], axis=1)\n\n# 构建双层前馈神经网络\ndef build_ffnn_model(input_shape):\n    model = Sequential()\n    model.add(Dense(64, activation='relu', input_shape=input_shape))\n    model.add(Dropout(0.3))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    return model\n\nffnn_model = build_ffnn_model((stacked_features.shape[1],))\n\nffnn_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n\n# 训练双层前馈神经网络\nffnn_model.fit(stacked_features, extra_y, epochs=10, batch_size=32, validation_split=0.2)\n\n# 在测试集上预测\ncnn_lstm_test_predictions = cnn_lstm_model.predict(test_X_pca)\ntwo_layer_lstm_test_predictions = two_layer_lstm_model.predict(test_X_pca)\nsingle_layer_lstm_test_predictions = single_layer_lstm_model.predict(test_X_pca)\n\n# 组合测试集预测结果作为新特征\nstacked_test_features = np.concatenate([cnn_lstm_test_predictions, two_layer_lstm_test_predictions, single_layer_lstm_test_predictions], axis=1)\n\n# 利用双层前馈神经网络进行最终预测\nfinal_predictions = ffnn_model.predict(stacked_test_features)\n\n# 保存结果\nresult = pd.DataFrame({'id': test_df['id'], 'Response': final_predictions.flatten()})\nresult.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-11T06:48:19.393726Z","iopub.execute_input":"2024-07-11T06:48:19.394362Z","iopub.status.idle":"2024-07-11T07:34:16.928856Z","shell.execute_reply.started":"2024-07-11T06:48:19.394330Z","shell.execute_reply":"2024-07-11T07:34:16.927937Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 6ms/step - accuracy: 0.8752 - loss: 0.2959 - val_accuracy: 0.8786 - val_loss: 0.2679\nEpoch 2/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.8776 - loss: 0.2710 - val_accuracy: 0.8786 - val_loss: 0.2688\nEpoch 3/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6ms/step - accuracy: 0.8782 - loss: 0.2695 - val_accuracy: 0.8786 - val_loss: 0.2670\nEpoch 4/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.8774 - loss: 0.2687 - val_accuracy: 0.8786 - val_loss: 0.2664\nEpoch 5/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.8761 - loss: 0.2694 - val_accuracy: 0.8786 - val_loss: 0.2675\nEpoch 6/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.8752 - loss: 0.2699 - val_accuracy: 0.8786 - val_loss: 0.2670\nEpoch 7/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.8776 - loss: 0.2669 - val_accuracy: 0.8784 - val_loss: 0.2664\nEpoch 8/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.8772 - loss: 0.2669 - val_accuracy: 0.8786 - val_loss: 0.2661\nEpoch 9/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.8779 - loss: 0.2653 - val_accuracy: 0.8788 - val_loss: 0.2655\nEpoch 10/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.8764 - loss: 0.2663 - val_accuracy: 0.8786 - val_loss: 0.2659\nEpoch 1/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - accuracy: 0.8770 - loss: 0.3255 - val_accuracy: 0.8786 - val_loss: 0.2712\nEpoch 2/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - accuracy: 0.8775 - loss: 0.2734 - val_accuracy: 0.8786 - val_loss: 0.2696\nEpoch 3/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.8759 - loss: 0.2729 - val_accuracy: 0.8786 - val_loss: 0.2674\nEpoch 4/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.8779 - loss: 0.2697 - val_accuracy: 0.8786 - val_loss: 0.2663\nEpoch 5/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.8771 - loss: 0.2698 - val_accuracy: 0.8786 - val_loss: 0.2679\nEpoch 6/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.8756 - loss: 0.2719 - val_accuracy: 0.8786 - val_loss: 0.2667\nEpoch 7/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.8757 - loss: 0.2692 - val_accuracy: 0.8786 - val_loss: 0.2689\nEpoch 8/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.8769 - loss: 0.2691 - val_accuracy: 0.8786 - val_loss: 0.2669\nEpoch 9/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.8757 - loss: 0.2699 - val_accuracy: 0.8786 - val_loss: 0.2655\nEpoch 10/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.8761 - loss: 0.2689 - val_accuracy: 0.8786 - val_loss: 0.2660\nEpoch 1/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.8755 - loss: 0.3390 - val_accuracy: 0.8786 - val_loss: 0.2742\nEpoch 2/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8767 - loss: 0.2744 - val_accuracy: 0.8786 - val_loss: 0.2715\nEpoch 3/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8755 - loss: 0.2730 - val_accuracy: 0.8786 - val_loss: 0.2690\nEpoch 4/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8756 - loss: 0.2727 - val_accuracy: 0.8786 - val_loss: 0.2663\nEpoch 5/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8784 - loss: 0.2690 - val_accuracy: 0.8786 - val_loss: 0.2670\nEpoch 6/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8760 - loss: 0.2696 - val_accuracy: 0.8786 - val_loss: 0.2656\nEpoch 7/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8768 - loss: 0.2690 - val_accuracy: 0.8786 - val_loss: 0.2673\nEpoch 8/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8759 - loss: 0.2700 - val_accuracy: 0.8786 - val_loss: 0.2681\nEpoch 9/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8772 - loss: 0.2673 - val_accuracy: 0.8786 - val_loss: 0.2660\nEpoch 10/10\n\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8762 - loss: 0.2678 - val_accuracy: 0.8786 - val_loss: 0.2652\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 105/2500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7839 - loss: 0.6330    ","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1720681289.827646     113 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8680 - loss: 0.3375 - val_accuracy: 0.8771 - val_loss: 0.2686\nEpoch 2/10\n\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8758 - loss: 0.2713 - val_accuracy: 0.8771 - val_loss: 0.2675\nEpoch 3/10\n\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8777 - loss: 0.2682 - val_accuracy: 0.8771 - val_loss: 0.2666\nEpoch 4/10\n\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8771 - loss: 0.2695 - val_accuracy: 0.8771 - val_loss: 0.2664\nEpoch 5/10\n\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8770 - loss: 0.2695 - val_accuracy: 0.8771 - val_loss: 0.2662\nEpoch 6/10\n\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8768 - loss: 0.2678 - val_accuracy: 0.8771 - val_loss: 0.2659\nEpoch 7/10\n\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8770 - loss: 0.2693 - val_accuracy: 0.8771 - val_loss: 0.2670\nEpoch 8/10\n\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8765 - loss: 0.2696 - val_accuracy: 0.8771 - val_loss: 0.2670\nEpoch 9/10\n\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8742 - loss: 0.2727 - val_accuracy: 0.8771 - val_loss: 0.2658\nEpoch 10/10\n\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8742 - loss: 0.2708 - val_accuracy: 0.8771 - val_loss: 0.2657\n\u001b[1m239684/239684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 2ms/step\n\u001b[1m239684/239684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 2ms/step\n\u001b[1m239684/239684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 1ms/step\n\u001b[1m239684/239684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 1ms/step\n","output_type":"stream"}]}]}