{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504ecfdf",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-11T07:50:53.505890Z",
     "iopub.status.busy": "2024-07-11T07:50:53.505022Z",
     "iopub.status.idle": "2024-07-11T07:50:54.335307Z",
     "shell.execute_reply": "2024-07-11T07:50:54.334365Z"
    },
    "papermill": {
     "duration": 0.837243,
     "end_time": "2024-07-11T07:50:54.337814",
     "exception": false,
     "start_time": "2024-07-11T07:50:53.500571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/binary/train.csv/train.csv\n",
      "/kaggle/input/binary/test.csv/test.csv\n",
      "/kaggle/input/binary-insurance/__results__.html\n",
      "/kaggle/input/binary-insurance/submission.csv\n",
      "/kaggle/input/binary-insurance/__notebook__.ipynb\n",
      "/kaggle/input/binary-insurance/__output__.json\n",
      "/kaggle/input/binary-insurance/custom.css\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f438e5d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T07:50:54.344790Z",
     "iopub.status.busy": "2024-07-11T07:50:54.344394Z",
     "iopub.status.idle": "2024-07-11T07:51:42.735471Z",
     "shell.execute_reply": "2024-07-11T07:51:42.734571Z"
    },
    "papermill": {
     "duration": 48.397285,
     "end_time": "2024-07-11T07:51:42.738024",
     "exception": false,
     "start_time": "2024-07-11T07:50:54.340739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 07:50:57.581804: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-11 07:50:57.581929: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-11 07:50:57.727747: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, LSTM, Input, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 数据预处理函数\n",
    "def preprocess_data(df):\n",
    "    label_enc = LabelEncoder()\n",
    "    categorical_columns = ['Gender', 'Vehicle_Age', 'Vehicle_Damage']\n",
    "    for col in categorical_columns:\n",
    "        df[col] = label_enc.fit_transform(df[col])\n",
    "    df.fillna(df.median(), inplace=True)\n",
    "    return df\n",
    "\n",
    "# 导入数据\n",
    "train_df0 = pd.read_csv('/kaggle/input/binary/train.csv/train.csv')\n",
    "test_df0 = pd.read_csv('/kaggle/input/binary/test.csv/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c59062f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T07:51:42.744915Z",
     "iopub.status.busy": "2024-07-11T07:51:42.744588Z",
     "iopub.status.idle": "2024-07-11T07:51:54.992863Z",
     "shell.execute_reply": "2024-07-11T07:51:54.991327Z"
    },
    "papermill": {
     "duration": 12.255964,
     "end_time": "2024-07-11T07:51:54.996969",
     "exception": false,
     "start_time": "2024-07-11T07:51:42.741005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 从训练集中提取200000个数据\n",
    "train_df = train_df0.sample(n=200000, random_state=42)\n",
    "extra_train_df = train_df0.drop(train_df.index).sample(n=100000, random_state=42)\n",
    "\n",
    "# 数据预处理\n",
    "train_df = preprocess_data(train_df)\n",
    "extra_train_df = preprocess_data(extra_train_df)\n",
    "test_df = preprocess_data(test_df0)\n",
    "\n",
    "# 特征和目标变量\n",
    "X = train_df.drop(columns=['Response', 'id'])\n",
    "y = train_df['Response']\n",
    "extra_X = extra_train_df.drop(columns=['Response', 'id'])\n",
    "extra_y = extra_train_df['Response']\n",
    "test_X = test_df.drop(columns=['id'])\n",
    "\n",
    "# 特征标准化\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "extra_X_scaled = scaler.transform(extra_X)\n",
    "test_X_scaled = scaler.transform(test_X)\n",
    "\n",
    "# PCA降维\n",
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "extra_X_pca = pca.transform(extra_X_scaled)\n",
    "test_X_pca = pca.transform(test_X_scaled)\n",
    "\n",
    "# 将特征扩展到3D以适应Conv1D和LSTM\n",
    "X_pca = np.expand_dims(X_pca, axis=2)\n",
    "extra_X_pca = np.expand_dims(extra_X_pca, axis=2)\n",
    "test_X_pca = np.expand_dims(test_X_pca, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dff67b3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T07:51:55.010783Z",
     "iopub.status.busy": "2024-07-11T07:51:55.010242Z",
     "iopub.status.idle": "2024-07-11T08:37:58.278057Z",
     "shell.execute_reply": "2024-07-11T08:37:58.277223Z"
    },
    "papermill": {
     "duration": 2763.277665,
     "end_time": "2024-07-11T08:37:58.280382",
     "exception": false,
     "start_time": "2024-07-11T07:51:55.002717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 6ms/step - accuracy: 0.8755 - loss: 0.2912 - val_accuracy: 0.8786 - val_loss: 0.2711\n",
      "Epoch 2/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.8780 - loss: 0.2714 - val_accuracy: 0.8786 - val_loss: 0.2673\n",
      "Epoch 3/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.8767 - loss: 0.2714 - val_accuracy: 0.8786 - val_loss: 0.2675\n",
      "Epoch 4/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.8760 - loss: 0.2699 - val_accuracy: 0.8786 - val_loss: 0.2669\n",
      "Epoch 5/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.8757 - loss: 0.2707 - val_accuracy: 0.8786 - val_loss: 0.2659\n",
      "Epoch 6/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.8760 - loss: 0.2682 - val_accuracy: 0.8786 - val_loss: 0.2666\n",
      "Epoch 7/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.8756 - loss: 0.2701 - val_accuracy: 0.8786 - val_loss: 0.2663\n",
      "Epoch 8/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6ms/step - accuracy: 0.8773 - loss: 0.2686 - val_accuracy: 0.8788 - val_loss: 0.2671\n",
      "Epoch 9/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.8759 - loss: 0.2674 - val_accuracy: 0.8787 - val_loss: 0.2681\n",
      "Epoch 10/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.8759 - loss: 0.2687 - val_accuracy: 0.8785 - val_loss: 0.2660\n",
      "Epoch 1/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - accuracy: 0.8752 - loss: 0.3308 - val_accuracy: 0.8786 - val_loss: 0.2731\n",
      "Epoch 2/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - accuracy: 0.8757 - loss: 0.2763 - val_accuracy: 0.8786 - val_loss: 0.2705\n",
      "Epoch 3/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.8772 - loss: 0.2720 - val_accuracy: 0.8786 - val_loss: 0.2695\n",
      "Epoch 4/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.8762 - loss: 0.2715 - val_accuracy: 0.8786 - val_loss: 0.2673\n",
      "Epoch 5/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.8751 - loss: 0.2721 - val_accuracy: 0.8786 - val_loss: 0.2674\n",
      "Epoch 6/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.8780 - loss: 0.2677 - val_accuracy: 0.8786 - val_loss: 0.2663\n",
      "Epoch 7/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.8772 - loss: 0.2686 - val_accuracy: 0.8786 - val_loss: 0.2656\n",
      "Epoch 8/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.8766 - loss: 0.2687 - val_accuracy: 0.8786 - val_loss: 0.2666\n",
      "Epoch 9/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.8770 - loss: 0.2682 - val_accuracy: 0.8786 - val_loss: 0.2652\n",
      "Epoch 10/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.8757 - loss: 0.2684 - val_accuracy: 0.8786 - val_loss: 0.2665\n",
      "Epoch 1/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8746 - loss: 0.3382 - val_accuracy: 0.8786 - val_loss: 0.2755\n",
      "Epoch 2/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8763 - loss: 0.2773 - val_accuracy: 0.8786 - val_loss: 0.2698\n",
      "Epoch 3/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8758 - loss: 0.2746 - val_accuracy: 0.8786 - val_loss: 0.2737\n",
      "Epoch 4/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8767 - loss: 0.2708 - val_accuracy: 0.8786 - val_loss: 0.2681\n",
      "Epoch 5/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8764 - loss: 0.2705 - val_accuracy: 0.8786 - val_loss: 0.2675\n",
      "Epoch 6/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8770 - loss: 0.2695 - val_accuracy: 0.8786 - val_loss: 0.2670\n",
      "Epoch 7/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8762 - loss: 0.2703 - val_accuracy: 0.8786 - val_loss: 0.2662\n",
      "Epoch 8/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8766 - loss: 0.2687 - val_accuracy: 0.8786 - val_loss: 0.2655\n",
      "Epoch 9/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8754 - loss: 0.2696 - val_accuracy: 0.8786 - val_loss: 0.2654\n",
      "Epoch 10/10\n",
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8762 - loss: 0.2688 - val_accuracy: 0.8786 - val_loss: 0.2659\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 107/2500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8329 - loss: 0.6032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1720685105.083791      69 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8736 - loss: 0.3287 - val_accuracy: 0.8771 - val_loss: 0.2687\n",
      "Epoch 2/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8749 - loss: 0.2732 - val_accuracy: 0.8771 - val_loss: 0.2673\n",
      "Epoch 3/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8774 - loss: 0.2689 - val_accuracy: 0.8771 - val_loss: 0.2662\n",
      "Epoch 4/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8743 - loss: 0.2725 - val_accuracy: 0.8771 - val_loss: 0.2670\n",
      "Epoch 5/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8772 - loss: 0.2683 - val_accuracy: 0.8771 - val_loss: 0.2668\n",
      "Epoch 6/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8762 - loss: 0.2685 - val_accuracy: 0.8771 - val_loss: 0.2696\n",
      "Epoch 7/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8777 - loss: 0.2688 - val_accuracy: 0.8771 - val_loss: 0.2661\n",
      "Epoch 8/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.2676 - val_accuracy: 0.8771 - val_loss: 0.2657\n",
      "Epoch 9/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8782 - loss: 0.2674 - val_accuracy: 0.8773 - val_loss: 0.2665\n",
      "Epoch 10/10\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8749 - loss: 0.2715 - val_accuracy: 0.8771 - val_loss: 0.2668\n",
      "\u001b[1m239684/239684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 2ms/step\n",
      "\u001b[1m239684/239684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 2ms/step\n",
      "\u001b[1m239684/239684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 1ms/step\n",
      "\u001b[1m239684/239684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# 构建CNN-LSTM模型\n",
    "def build_cnn_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(LSTM(70, return_sequences=True))\n",
    "    model.add(LSTM(70))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# 构建双层LSTM模型\n",
    "def build_two_layer_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(70, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(70))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# 构建单层LSTM模型\n",
    "def build_single_layer_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(70, input_shape=input_shape))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "input_shape = (X_pca.shape[1], 1)\n",
    "\n",
    "cnn_lstm_model = build_cnn_lstm_model(input_shape)\n",
    "two_layer_lstm_model = build_two_layer_lstm_model(input_shape)\n",
    "single_layer_lstm_model = build_single_layer_lstm_model(input_shape)\n",
    "\n",
    "cnn_lstm_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "two_layer_lstm_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "single_layer_lstm_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练三个子模型\n",
    "cnn_lstm_model.fit(X_pca, y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "two_layer_lstm_model.fit(X_pca, y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "single_layer_lstm_model.fit(X_pca, y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# 获取三个子模型的预测结果\n",
    "cnn_lstm_predictions = cnn_lstm_model.predict(extra_X_pca)\n",
    "two_layer_lstm_predictions = two_layer_lstm_model.predict(extra_X_pca)\n",
    "single_layer_lstm_predictions = single_layer_lstm_model.predict(extra_X_pca)\n",
    "\n",
    "# 组合预测结果作为新特征\n",
    "stacked_features = np.concatenate([cnn_lstm_predictions, two_layer_lstm_predictions, single_layer_lstm_predictions], axis=1)\n",
    "\n",
    "# 构建双层前馈神经网络\n",
    "def build_ffnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "ffnn_model = build_ffnn_model((stacked_features.shape[1],))\n",
    "\n",
    "ffnn_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练双层前馈神经网络\n",
    "ffnn_model.fit(stacked_features, extra_y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# 在测试集上预测\n",
    "cnn_lstm_test_predictions = cnn_lstm_model.predict(test_X_pca)\n",
    "two_layer_lstm_test_predictions = two_layer_lstm_model.predict(test_X_pca)\n",
    "single_layer_lstm_test_predictions = single_layer_lstm_model.predict(test_X_pca)\n",
    "\n",
    "# 组合测试集预测结果作为新特征\n",
    "stacked_test_features = np.concatenate([cnn_lstm_test_predictions, two_layer_lstm_test_predictions, single_layer_lstm_test_predictions], axis=1)\n",
    "\n",
    "# 利用双层前馈神经网络进行最终预测\n",
    "final_predictions = ffnn_model.predict(stacked_test_features)\n",
    "\n",
    "# 保存结果\n",
    "result = pd.DataFrame({'id': test_df['id'], 'Response': final_predictions.flatten()})\n",
    "result.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5369298,
     "sourceId": 8926339,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 187760598,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2834.488271,
   "end_time": "2024-07-11T08:38:05.196271",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-11T07:50:50.708000",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
